{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW4 Task2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder, PolynomialFeatures,scale\n",
    "from sklearn.linear_model import LogisticRegressionCV, LogisticRegression, LinearRegression,Ridge, Lasso, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.compose import make_column_transformer, ColumnTransformer, make_column_selector\n",
    "from sklearn.pipeline import make_pipeline,Pipeline\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import SimpleImputer, KNNImputer,IterativeImputer\n",
    "from category_encoders.target_encoder import TargetEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, TfidfTransformer\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.corpora import WikiCorpus\n",
    "from gensim.models import word2vec\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleansing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path1 = \"/Users/racheltan/Desktop/QMSS/AML/winemag-data-130k-v2.csv\"\n",
    "path2 = \"/Users/ellen/Documents/GitHub/assignment-4-rachel_ellen/wine-reviews/winemag-data-130k-v2.csv\"\n",
    "\n",
    "wine_raw = pd.read_csv(path2, index_col = 0).drop(['taster_name', 'taster_twitter_handle'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "wine_usa = wine_raw[wine_raw.country == 'US']\n",
    "wine_usa_skew = wine_usa[wine_usa.price < 250].drop_duplicates('description') #using wine only from US, remove duplicate rows\n",
    "wine_us = wine_usa_skew.sample(n = 20000, random_state = 123) #subsample 20k rows \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "wine_us=wine_us.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Use a pretrained word-embedding (word2vec, glove or fasttext) for featurization instead of the\n",
    "bag-of-words model. Does this improve classification? How about combining the embedded\n",
    "words with the BoW model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_us[\"description_punc\"]=0\n",
    "wine_us[\"title_punc\"]=0\n",
    "\n",
    "for i in range(len(wine_us)):\n",
    "    wine_us.loc[i,\"description_punc\"] = re.sub(\"[^a-zA-Z']+\", ' ', wine_us['description'][i]) \n",
    "    wine_us.loc[i,\"title_punc\"] = re.sub(\"[^a-zA-Z']+\", ' ', wine_us['description'][i])\n",
    "    wine_us.loc[i,\"description_punc\"] = wine_us.loc[i,\"description_punc\"].lower()\n",
    "    wine_us.loc[i,\"title_punc\"] = wine_us.loc[i,\"title_punc\"].lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    this is a relatively thick and dense wine grip...\n",
       "1    a routine although entirely drinkable merlot i...\n",
       "2    tremendously rich and oaky with butterscotch i...\n",
       "3    white pepper dominates the smell and the flavo...\n",
       "4    this yakima valley bottling highlights fresh h...\n",
       "Name: description_punc, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_us[\"description_punc\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_full = wine_us[['description','description_punc','designation', 'price', 'province', 'region_1', 'region_2','variety','winery', 'title',\"title_punc\"]] #take out title \n",
    "y_full = wine_us['points']\n",
    "X_full_train, X_full_test, y_full_train, y_full_test = train_test_split(X_full,y_full,test_size=0.2,random_state=30)\n",
    "X_full_train = X_full_train.reset_index().drop('index',axis=1)\n",
    "y_full_train = y_full_train.reset_index().drop('index',axis=1)\n",
    "X_full_test = X_full_test.reset_index().drop('index',axis=1)\n",
    "y_full_test = y_full_test.reset_index().drop('index',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16000, 300)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\", disable=[\"tagger\", \"parser\", \"ner\"])\n",
    "docs_train = [nlp(d).vector for d in X_full_train[\"description_punc\"]]\n",
    "X_train = np.vstack(docs_train)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5528940232729389"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "Ridge_w2v = Ridge().fit(X_train, y_full_train)\n",
    "Ridge_w2v.score(X_train, y_full_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5280946595663794"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test\n",
    "docs_val = [nlp(d).vector for d in X_full_test[\"description_punc\"]]\n",
    "X_val = np.vstack(docs_val)\n",
    "Ridge_w2v.score(X_val, y_full_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we combined description and title:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16000, 600)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_train = [nlp(d).vector for d in X_full_train[\"title_punc\"]]\n",
    "X_title = np.vstack(title_train)\n",
    "X_train2 = np.hstack((X_train,X_title))\n",
    "X_train2.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5538889576141489"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "Ridge_w2v = Ridge().fit(X_train2, y_full_train)\n",
    "Ridge_w2v.score(X_train2, y_full_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5278713969428191"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test\n",
    "title_val = [nlp(d).vector for d in X_full_test[\"title_punc\"]]\n",
    "X_titleval = np.vstack(title_val)\n",
    "X_val2 = np.hstack((X_val,X_titleval))\n",
    "\n",
    "Ridge_w2v.score(X_val2, y_full_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We reached a score 0.5529 for train data and 0.528 for test data. When we add both description and title, the score hasn't changed much.\n",
    "\n",
    "### Combine the embedded words and the BOW words together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "my_stopwords = set(ENGLISH_STOP_WORDS)\n",
    "my_stopwords.remove(\"well\")\n",
    "my_stopwords.remove(\"not\")\n",
    "my_stopwords.add(\"ve\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = [nlp(d).vector for d in X_full[\"title_punc\"]]\n",
    "description = [nlp(d).vector for d in X_full[\"description_punc\"]]\n",
    "\n",
    "X_Tfidf = np.hstack((title,description))\n",
    "X_Tfidf = pd.DataFrame(X_train_Tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Tfidf['description_bow'] = X_full[\"description_punc\"]\n",
    "X_Tfidf['title_bow'] = X_full[\"title_punc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tfi_train, X_tfi_test, y_tfi_train, y_tfi_test = train_test_split(X_Tfidf,y_full,test_size=0.2,random_state=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.693898121413947"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using characters instead of words \n",
    "\n",
    "tfidf_vect2 = TfidfVectorizer(stop_words = my_stopwords, ngram_range = (2,5), min_df = 3, analyzer=\"char\")\n",
    "preprocess2 = make_column_transformer(    \n",
    "    (tfidf_vect2, 'description_bow'), \n",
    "    (tfidf_vect2, 'title_bow'))\n",
    "\n",
    "tfidf_ridge2 = make_pipeline(preprocess2, Ridge(alpha = 1.0))\n",
    "score_tfidf_ridge2 = cross_val_score(tfidf_ridge2, X_tfi_train, y_tfi_train)\n",
    "np.mean(score_tfidf_ridge2) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part we combine the BOW words with embedded word together. The score goes up to 0.69"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original BOW with re text prepoccessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_full = wine_us[['description','description_punc','designation', 'price', 'province', 'region_1', 'region_2','variety','winery', 'title',\"title_punc\"]] #take out title \n",
    "y_full = wine_us['points']\n",
    "X_full_train, X_full_test, y_full_train, y_full_test = train_test_split(X_full,y_full,test_size=0.2,random_state=30)\n",
    "X_full_train = X_full_train.reset_index().drop('index',axis=1)\n",
    "y_full_train = y_full_train.reset_index().drop('index',axis=1)\n",
    "X_full_test = X_full_test.reset_index().drop('index',axis=1)\n",
    "y_full_test = y_full_test.reset_index().drop('index',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vect = TfidfVectorizer(stop_words = my_stopwords, ngram_range = (2,5), min_df = 2, analyzer=\"char\") #tfidf vectorizer is the same as count vec + tfidf transformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_bow_train = tfidf_vect.fit_transform(X_full_train['description_punc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8431906240825124"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge3 = Ridge(alpha = 1.0).fit(X_bow_train, y_full_train)\n",
    "ridge3.score(X_bow_train, y_full_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with the help of re prepocessing, the bow score goes up to 0.84"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
